# ğŸ’³ Credit Card Fraud Detection

---

## ğŸ“Œ Problem Statement

Credit card fraud detection is a **major challenge** for financial institutions because:  

- **âš  Highly Imbalanced Data:** Fraudulent transactions are extremely rare compared to legitimate ones.  
- **ğŸ” Feature Complexity:** Dataset contains both **numerical** and **categorical** features requiring careful preprocessing.  
- **âš¡ Real-time Detection Requirements:** Must be **accurate, efficient, and scalable** for real-world usage.  

### ğŸ¯ Objective  
Develop a **robust machine learning model** that:  
âœ” Accurately identifies fraudulent transactions  
âœ” Minimizes **false positives**  
âœ” Handles **class imbalance** effectively  

---

## âœ… Proposed Solution

The system follows a **supervised machine learning pipeline** with these key stages:

---

### **1ï¸âƒ£ Data Acquisition & Exploration**
- Loaded the credit card transaction dataset: **`train.csv`**  
- Performed **EDA**:  
  âœ” Data shape & summary statistics  
  âœ” Missing value checks  

---

### **2ï¸âƒ£ Data Preprocessing & Feature Engineering**
- Converted **transaction timestamps** â†’ datetime format and extracted **day of the week**  
- Calculated **customer age** from **DOB**  
- Removed **irrelevant columns** (IDs, non-informative fields)  
- Applied:  
  âœ” **Label Encoding** for categorical variables  
  âœ” **StandardScaler** for numerical feature scaling  

---

### **3ï¸âƒ£ Handling Imbalanced Data**
Due to extreme class imbalance, multiple strategies were applied:  
âœ” **Class Weight Balancing** in Logistic Regression  
âœ” **Undersampling** (reduce majority class)  
âœ” **Oversampling** using **Random Oversampling**  

---

### **4ï¸âƒ£ Model Development & Training**
Implemented and compared **multiple classification models**:  
- **Logistic Regression (Vanilla)**  
- **Logistic Regression with Class Weights**  
- **Logistic Regression on Undersampled Data**  
- **Logistic Regression on Oversampled Data**  
- **Random Forest Classifier** (on resampled data)  

**Data Splitting:**  
- **Training**, **Validation**, and **Test sets** for unbiased evaluation  

---

### **5ï¸âƒ£ Model Evaluation**
Models were evaluated using:  
âœ” **Accuracy Score**  
âœ” **Classification Report** (Precision, Recall, F1-score)  
âœ” **Confusion Matrix**  

**Key Metric:**  
- Special focus on **Recall for fraud class** (detecting fraud is critical âœ…)  

---

### **6ï¸âƒ£ Insights & Observations**
ğŸ“Œ Models using **class balancing techniques** performed better.  
ğŸ“Œ **Random Forest** and **Balanced Logistic Regression** gave **most reliable results**.  
ğŸ“Œ Vanilla models struggled with detecting rare fraud cases.  

---

## ğŸ“Š Results Snapshot
| Model                                  | Precision | Recall | F1-Score |
|---------------------------------------|-----------|--------|----------|
| Logistic Regression (Vanilla)        | Low       | Very Low | Poor     |
| Logistic Regression (Balanced)       | Medium    | High   | Good     |
| Random Forest (Resampled Data)       | High      | High   | Excellent |

---

## ğŸ›  Tech Stack
- **Language:** Python ğŸ  
- **Libraries:** pandas, numpy, scikit-learn, matplotlib, seaborn  

---

## ğŸš€ Future Improvements
âœ” Implement **SMOTE** for better oversampling  
âœ” Try **Gradient Boosting** & **XGBoost** for higher accuracy  
âœ” Deploy as **Flask/FastAPI API** for real-time fraud detection  

---

â­ **If you found this project useful, don't forget to give it a STAR!** â­
